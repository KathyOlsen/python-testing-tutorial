{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Testing Tutorial\n",
    "\n",
    "Welcome to the Python Testing Tutorial notebook. This will be the resource we use to both learn, and test what we learned. This notebook is designed to be loaded to a Jupyter Lab instance that has `pytest` and `ipython_pytest` installed. In a new virtual environment, do\n",
    "\n",
    "```\n",
    "$ pip install pytest ipython_pytest jupyterlab\n",
    "```\n",
    "\n",
    "When this is done, launch Jupyter\n",
    "\n",
    "```\n",
    "$ jupyter lab\n",
    "```\n",
    "\n",
    "Click on the upload icon, and upload this notebook.\n",
    "\n",
    "The next step will be to load the `ipython_test` Jupyter extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ipython_pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should not be any output from this step. If an error occured saying it is not installed, make sure the virtual environment has `ipython_test` installed.\n",
    "\n",
    "Next, we will run one test, just to see what failure looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pytest\n",
    "\n",
    "def test_something():\n",
    "    assert [1] == [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your test didn't run, or you did not get a failure that looks like\n",
    "\n",
    "```\n",
    "    def test_something():\n",
    ">       assert [1] == [2]\n",
    "E       assert [1] == [2]\n",
    "E         At index 0 diff: 1 != 2\n",
    "E         Use -v to get the full diff\n",
    "\n",
    "_ipytesttmp.py:3: AssertionError\n",
    "```\n",
    "\n",
    "Then something might not be installed and configured properly. Check again that `pytest` and `ipython_pytest` are properly installed in your virtual environment.\n",
    "\n",
    "The mechanics of running tests differ between environments. Usually, you will be running the `pytest` command-line -- but quite often, not directly. You might be using a `tox` runner, run the tests in a Continuous Integration environment, or maybe inside a Docker container. Regardless, most of the effort will be spent writing tests and looking at test failures -- and this is going to be what this tutorial will cover.\n",
    "\n",
    "Pytest uses the Python keyword `assert` in order to check conditions in tests. It internally processes this statement to help failures look nicer. We already saw that it does a checks the difference with a list of one element. Let's see a few more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pytest\n",
    "\n",
    "def test_missing():\n",
    "    assert [1] == []\n",
    "    \n",
    "def test_extra():\n",
    "    assert [1] == [1, 2]\n",
    "    \n",
    "def test_different():\n",
    "    assert [1, 2, 3] == [1, 4, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tests failed here -- but read the output carefully to see *how* they failed. When writing tests for new code, much of your work will be analyzing test failures to understand how they failed, and whether the test code or product code is broken. If the tests are doing their job to prevent regressions, much of your work will be looking at test failures to understand whether you need to fix the code or modify an out-of-date test.\n",
    "\n",
    "The most interesting thing about any test framework is how test failures look.\n",
    "\n",
    "Let's see how `pytest` handles other equality failures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pytest\n",
    "\n",
    "def test_string():\n",
    "    assert \"hello\\nworld\" == \"goodbye\\nworld\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For strings, `pytest` will do a line-by-line diff to highlight differences. However, it will not do inside-line-diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
